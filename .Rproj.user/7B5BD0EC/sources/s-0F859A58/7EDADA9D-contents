---
title: "$m$-weights"
author: Adam Howes
output:
  pdf_document: default
  html_document:
    df_print: paged
editor_options:
  chunk_output_type: inline
---

## Introduction

In spatial epidemiology and public health, we often model an embedding of individuals into space.
Spatial smoothing is then described as "borrowing information between areas", despite the fact that the information is a property of individuals not of space.

The Besag model 
$$
\phi_i \, | \, \phi_{-i} \sim \mathcal{N} \left(\frac{\sum_{j: j \sim i} \phi_j}{n_{\delta i}}, \frac{1}{n_{\delta i}\tau_\phi}\right)
$$
was originally designed for image analysis, where information truly is a property of space.
In an image each pixel represents a certain fixed number of bits of information.
Higher pixel density represents higher information density.

More general Gaussian Markov random field models may be specified by
$$
\phi_i \, | \, \phi_{-i} \sim \mathcal{N} \left(\frac{\sum_{j: j \sim i} w_{ij} \phi_j}{\kappa_i}, \frac{1}{\kappa_i \tau_\phi}\right),
$$
where $\kappa_i = \sum_{k: k \sim i} w_{ij}$.
Within this setting, individuals may be taken into account by setting $w_{ij} = m_i m_j$, giving spatial random effects with mean
$$
\mathbb{E}(\phi_i \, | \, \phi_{-i}) 
= \sum_{j: j \sim i} \frac{m_i m_j \phi_j}{\sum_{k: k \sim i} m_i m_j} 
= \frac{1}{\sum_{k: k \sim i} m_k} \sum_{j: j \sim i} m_j \phi_j
$$
and precision $\mathbb{V}^{-1}(\phi_i \, | \, \phi_{-i}) \propto m_i \sum_{k: k \sim i} m_k$.
Each neighbouring area is borrowed from in proportion to the number of individuals in it, and thus the information it has to offer. 
The precision of the spatial random effect is proportional to the total sample size in neighbouring areas.
This specification could be extended by taking into account the relevance of the information as determined by spatial proximity.

Uncertainties:

* Maybe this can be formalised more by writing an a priori correlation structure between individuals, and then finding the spatial correlation structure that results
* How does $m_i$ impact $\phi_j, \, j \sim i$ with the Besag model already?
* Is there a flow of information already whereby higher sample size creates more precise estimates of $\phi_i$ which then impacts the precision of $\phi_j$? Write out the full posterior to see this properly.

\newpage

## Example

```{r message=FALSE}
library(INLA)
library(bsae)
```

Three areas in a line 1-2-3.
In area 1 we only test a single person and they're positive.
In area 3 we test 100 people and none of them are positive.
It's reasonable that the middle should be smoothed lower than 0.2: at least to me, 0/100 is much more convincing than 1/1.


```{r}
dat <- list(
  id = 1:3,
  y = c(1, 1, 0),
  m = c(1, 5, 100)
)
```

Adjacency matrix:

```{r}
adj <- rbind(c(0, 1, 0),
             c(0, 0, 1),
             c(0, 0, 0))

adj <- adj + t(adj)
```

### Smoothing with `"besag"`

Precision prior and random effect formula:

```{r}
tau_prior <- list(prec = list(prior = "loggamma", param = c(1, 1), initial = 1, fixed = FALSE))

formula <- y ~ 1 + f(id, 
                     model = "besag", 
                     graph = adj, 
                     scale.model = TRUE, 
                     constr = TRUE, 
                     hyper = tau_prior)

fit <- INLA::inla(formula,
                  family = "binomial",
                  control.family = list(control.link = list(model = "logit")),
                  data = dat,
                  Ntrials = m,
                  control.predictor = list(compute = TRUE, link = 1))

fit$summary.fitted.values
```
`fitted.Predictor.2` has mean `r fit$summary.fitted.values[2, 1]`.
The mode is `r fit$summary.fitted.values[2, "mode"]`

```{r}
plot(fit$marginals.fitted.values[[2]], type = "l")
```

\newpage

### Jeff's version

Jeff tried fitting this with `"rw1"` (the same as `"besag"` in one dimension) and with a default prior and got quite different results.

```{r}
formula_jeff <- y ~ 1 + f(id, model = "rw1")

fit_jeff <- INLA::inla(formula_jeff,
                       family = "binomial",
                       control.family = list(control.link = list(model = "logit")),
                       data = dat,
                       Ntrials = m,
                      control.predictor = list(compute = TRUE, link = 1))

fit_jeff$summary.fitted.values
```

With this prior on the precision (I should check exactly what it is) all of the fitted values are close to zero (even in the first area).

```{r}
plot(fit_jeff$marginals.fitted.values[[2]], type = "l")
```

\newpage

### Smoothing with `"wicar"`

In `INLA` new models can be defined using the "`rgeneric`" functionality.
Here I do that for a weighted ICAR model.
I should be using the same Gamma precision prior as in `tau_prior`.

```{r}
inla.rgeneric.wicar.model <-function(cmd = c("graph", "Q", "mu", "initial","log.norm.const", "log.prior", "quit"), theta = NULL) {
  envir <-parent.env(environment())
  
  interpret.theta <-function() {
    # L is used for integers, possibly faster / less memory
    return(list(prec =exp(theta[1L])))
  }
  
  graph <-function() {
    return(Q())
  }
  
  Q <-function() {
    p <-interpret.theta()
    return(p$prec*R) # This stays sparse
  }
  
  mu <-function() {
    return(numeric(0))
  }
  
  log.norm.const <-function() {
    return(numeric(0)) # Compute it yourself please!
  }
  
  log.prior <-function() {
    # Copying Havard's Gamma precision prior
    p <-interpret.theta()
    val <-dgamma(p$prec, shape = 1, rate = 1, log = TRUE) + theta[1L]
    return(val)
  }
  
  initial <-function() {
    return(1)
  }
  
  quit <-function() {
    return(invisible())
  }
  
  if(is.null(theta)) {
    theta <-initial()
  }
  
  val <-do.call(match.arg(cmd), args =list())
  return(val)
}
```

Create sample size weighted ICAR structure matrix, with scaling:

```{r}
M <- dat$m %*% t(dat$m) * adj
R <- diag(rowSums(M)) - M

R # This is the "unscaled" structure matrix, in that it doesn't have generalised variance of one

R_scaled <- bsae::scale_gmrf_precision(R)$Q
R_scaled <- as(R_scaled, "sparseMatrix")

R_scaled # And this is the scaled version, in "sparseMatrix" form
```

Fit it:

```{r}
wicar <- INLA::inla.rgeneric.define(inla.rgeneric.wicar.model, R = R_scaled)

formula <- y ~ 1 + f(id, model = wicar)

fit3 <- INLA::inla(formula,
                   family = "binomial",
                   control.family = list(control.link = list(model = "logit")),
                   data = dat,
                   Ntrials = m,
                   control.predictor = list(compute = TRUE, link = 1),
                   verbose = TRUE)

fit3$summary.fitted.values
plot(fit3$marginals.fitted.values[[2]], type = "l")
```
Now the prediction in area 2 is very close to that in area 3, maybe too much.
You can use some function of $m_i$ to reduce the effect e.g. $\log m_i$.